{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5gXNfcVjvDc"
      },
      "source": [
        "# Topic modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbHvJ-_I0Wx7"
      },
      "outputs": [],
      "source": [
        "# !pip install -U pip wheel\n",
        "# !pip install -U topic-wizard tqdm pandas orjson"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C36S18zo8w3b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import orjson\n",
        "import topicwizard\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFAu1Sgxsydd",
        "outputId": "bc9aa14d-c79e-482a-fbfb-a97d7c65b968"
      },
      "outputs": [],
      "source": [
        "# corpus\n",
        "path_corpus=os.path.expanduser('~/ppa_data/solrcorpus')\n",
        "path_metadata = os.path.join(path_corpus, 'metadata.csv')\n",
        "path_minimal = os.path.join(path_corpus, 'minimal.jsonl')\n",
        "path_texts = os.path.join(path_corpus, 'texts')\n",
        "path_minimal_numlines=None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TeT1qRuDtPtn",
        "outputId": "ad89b624-cfc7-4c98-9fcf-c743aa8542d8"
      },
      "outputs": [],
      "source": [
        "# Read metadata\n",
        "df_metadata = pd.read_csv(path_metadata).fillna('').set_index('work_id')\n",
        "# df_metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcRHm7iet_jz"
      },
      "outputs": [],
      "source": [
        "# def iter_id_tokens(min_word_len=4, min_num_words=25):\n",
        "#     global path_minimal_numlines\n",
        "#     if path_minimal_numlines == None:\n",
        "#         with open(path_minimal) as f:\n",
        "#             path_minimal_numlines = sum(1 for line in tqdm(f,desc='Getting number of lines',position=0))\n",
        "\n",
        "#     with open(path_minimal) as f:\n",
        "#         for ln in tqdm(f,total=path_minimal_numlines,desc='Iterating over jsonl',position=0):\n",
        "#             try:\n",
        "#                 d=orjson.loads(ln)\n",
        "#             except Exception:\n",
        "#                 continue\n",
        "#             toks = [\n",
        "#                 x \n",
        "#                 for x in d['toks'] \n",
        "#                 if not min_word_len or len(x)>=min_word_len\n",
        "#             ]\n",
        "#             if not min_num_words or len(toks)>=min_num_words:\n",
        "#                 yield (d['id'], toks)\n",
        "\n",
        "\n",
        "# def iter_tokens(lim=None,**kwargs):\n",
        "#     for i,(id,toks) in enumerate(iter_id_tokens(**kwargs)):\n",
        "#         yield toks\n",
        "#         if lim and i+1>=lim: break\n",
        "\n",
        "# def iter_tokens_txt(**kwargs):\n",
        "#     for x in iter_tokens(**kwargs):\n",
        "#         yield ', '.join(x)\n",
        "\n",
        "# # next(iter_id_tokens())\n",
        "# # next(iter_tokens())\n",
        "# # list(iter_tokens(1))\n",
        "# next(iter_tokens_txt())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gzip,random\n",
        "\n",
        "def iter_pages(lim=None,min_num_words=25,max_pages_per_doc=1):\n",
        "    num=0\n",
        "    for work_id in tqdm(df_metadata.index,desc='Iterating files'):\n",
        "        fn = os.path.join(path_texts,work_id+'.json.gz')\n",
        "        if not os.path.exists(fn): continue\n",
        "        with gzip.open(fn,'rt') as f:\n",
        "            data = orjson.loads(f.read())\n",
        "    \n",
        "        odata=[]\n",
        "        for paged in data:\n",
        "            if not min_num_words or len(paged.get('page_tokens',[]))>=min_num_words:\n",
        "                odata.append(paged)\n",
        "        \n",
        "        if max_pages_per_doc:\n",
        "            random.shuffle(odata)\n",
        "            odata=odata[:max_pages_per_doc]\n",
        "\n",
        "        yield from odata\n",
        "        \n",
        "        num+=len(odata)\n",
        "        if lim and num>=lim: break\n",
        "\n",
        "def iter_pages_text(**kwargs):\n",
        "    yield from (d.get('page_text_clean','') for d in iter_pages(**kwargs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "def get_corpus(force=False):\n",
        "    fn='data.topicwizard.corpus.pkl'\n",
        "    if not force and os.path.exists(fn):\n",
        "        with open(fn,'rb') as f: \n",
        "            return pickle.load(f)\n",
        "    \n",
        "    def iter_corpus(): \n",
        "        yield from iter_pages()\n",
        "    corpus = []\n",
        "    docids = []\n",
        "    clusterids = []\n",
        "    for d in iter_corpus():\n",
        "        corpus.append(d['page_text_clean'])\n",
        "        docids.append(d['page_id'])\n",
        "        clusterids.append(d['work_cluster'])\n",
        "\n",
        "    fn='data.topicwizard.corpus.pkl'\n",
        "    pkg=(corpus,docids,clusterids)\n",
        "    with open(fn,'wb') as of:\n",
        "        pickle.dump(pkg, of)\n",
        "    \n",
        "    return pkg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corpus,docids,clusterids = get_corpus(force=True)\n",
        "len(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import NMF\n",
        "from topicwizard.pipeline import make_topic_pipeline\n",
        "\n",
        "vectorizer = CountVectorizer(min_df=5, max_df=0.8, stop_words=\"english\")\n",
        "model = NMF(n_components=50)\n",
        "pipeline = make_topic_pipeline(vectorizer, model, pandas_out=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline.fit(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ryanheuser/.pyenv/versions/3.10.7/lib/python3.10/site-packages/topicwizard/prepare/topics.py:92: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/Users/ryanheuser/.pyenv/versions/3.10.7/lib/python3.10/site-packages/topicwizard/prepare/topics.py:94: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/Users/ryanheuser/.pyenv/versions/3.10.7/lib/python3.10/site-packages/topicwizard/prepare/topics.py:92: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/Users/ryanheuser/.pyenv/versions/3.10.7/lib/python3.10/site-packages/topicwizard/prepare/topics.py:94: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/Users/ryanheuser/.pyenv/versions/3.10.7/lib/python3.10/site-packages/topicwizard/prepare/topics.py:92: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/Users/ryanheuser/.pyenv/versions/3.10.7/lib/python3.10/site-packages/topicwizard/prepare/topics.py:94: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/Users/ryanheuser/.pyenv/versions/3.10.7/lib/python3.10/site-packages/topicwizard/prepare/topics.py:92: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/Users/ryanheuser/.pyenv/versions/3.10.7/lib/python3.10/site-packages/topicwizard/prepare/topics.py:94: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/Users/ryanheuser/.pyenv/versions/3.10.7/lib/python3.10/site-packages/topicwizard/prepare/topics.py:92: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/Users/ryanheuser/.pyenv/versions/3.10.7/lib/python3.10/site-packages/topicwizard/prepare/topics.py:94: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/Users/ryanheuser/.pyenv/versions/3.10.7/lib/python3.10/site-packages/topicwizard/prepare/topics.py:92: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/Users/ryanheuser/.pyenv/versions/3.10.7/lib/python3.10/site-packages/topicwizard/prepare/topics.py:94: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "res=topicwizard.visualize(\n",
        "    corpus, \n",
        "    pipeline=pipeline,\n",
        "    document_names=docids,\n",
        "    group_labels=clusterids\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from topicwizard.figures import topic_barcharts,word_map\n",
        "\n",
        "# topic_barcharts(corpus, pipeline=pipeline, top_n=5)\n",
        "word_map(corpus, pipeline=pipeline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
