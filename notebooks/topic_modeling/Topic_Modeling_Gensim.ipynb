{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uY5folNjvDZ"
      },
      "source": [
        "<a href=\"http://colab.research.google.com/github/dipanjanS/nlp_workshop_odsc19/blob/master/Module05%20-%20NLP%20Applications/Project04%20-%20Topic%20Modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5gXNfcVjvDc"
      },
      "source": [
        "# Topic Modeling on Research Papers\n",
        "\n",
        "We will do an interesting exercise here—build topic models on past research papers\n",
        "from the very popular NIPS conference (now known as the NeurIPS conference). The\n",
        "late professor Sam Roweis compiled an excellent collection of NIPS Conference Papers\n",
        "from Volume 1 – 12, which you can find at https://cs.nyu.edu/~roweis/data.html.\n",
        "An interesting fact is that he obtained this by massaging the OCR’d data from NIPS\n",
        "1-12, which was actually the pre-electronic submission era. Yann LeCun made the data\n",
        "available. There is an even more updated dataset available up to NIPS 17 at http://\n",
        "ai.stanford.edu/~gal/data.html. However, that dataset is in the form of a MAT file, so\n",
        "you might need to do some additional preprocessing before working on it in Python.\n",
        "\n",
        "\n",
        "# The Main Objective\n",
        "\n",
        "Considering our discussion so far, our main objective is pretty simple. Given a whole\n",
        "bunch of conference research papers, can we identify some key themes or topics from\n",
        "these papers by leveraging unsupervised learning? We do not have the liberty of labeled\n",
        "categories telling us what the major themes of every research paper are. Besides that, we\n",
        "are dealing with text data extracted using OCR (optical character recognition). Hence,\n",
        "you can expect misspelled words, words with characters missing, and so on, which\n",
        "makes our problem even more challenging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsTqya546U6q"
      },
      "source": [
        "# Download Data and Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lbHvJ-_I0Wx7"
      },
      "outputs": [],
      "source": [
        "# !pip install -qU pip wheel\n",
        "# !pip install -qU gensim tqdm pandas nltk numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "L-GrdJnV1Pah",
        "outputId": "1deecd40-f6c6-4d92-f2d1-5eab3f02c1a9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'4.3.2'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gensim\n",
        "gensim.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "C36S18zo8w3b"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFAu1Sgxsydd",
        "outputId": "bc9aa14d-c79e-482a-fbfb-a97d7c65b968"
      },
      "outputs": [],
      "source": [
        "# corpus\n",
        "# Mount google drive and set path to corpus\n",
        "path_corpus=os.path.expanduser('~/ppa_data/corpus_solr')\n",
        "path_metadata = os.path.join(path_corpus, 'metadata.csv')\n",
        "path_texts = os.path.join(path_corpus, 'texts')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TeT1qRuDtPtn",
        "outputId": "ad89b624-cfc7-4c98-9fcf-c743aa8542d8"
      },
      "outputs": [],
      "source": [
        "# Read metadata\n",
        "df_metadata = pd.read_csv(path_metadata).fillna('')\n",
        "# df_metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "g9PDqocqtlHd"
      },
      "outputs": [],
      "source": [
        "# Read jsons\n",
        "import gzip,json\n",
        "\n",
        "def get_work_json(work_id):\n",
        "    fn=os.path.join(path_texts, work_id+'.json.gz')\n",
        "    try:\n",
        "        with gzip.open(fn,mode='rt') as f:\n",
        "            return json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        pass\n",
        "    return []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IyI4ajk6tvDF"
      },
      "outputs": [],
      "source": [
        "# os.listdir(path_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QDvASAowtt66"
      },
      "outputs": [],
      "source": [
        "# get_work_json('CW0115427928')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fbBbUC6FuNW2"
      },
      "outputs": [],
      "source": [
        "def get_work_tokens(work_id):\n",
        "    work_tokens = []\n",
        "    for paged in get_work_json(work_id):\n",
        "        page_id = paged['page_id']\n",
        "\n",
        "        #@TODO: FIX\n",
        "        if not page_id:\n",
        "            page_id = f'{paged[\"work_source\"]}_{paged[\"page_orig\"]}'\n",
        "        tokens = [tok.lower() for tok in paged['page_tokens']]\n",
        "        work_tokens.append((page_id, tokens))\n",
        "    return work_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "NQbvsSr5ubzm"
      },
      "outputs": [],
      "source": [
        "# get_work_tokens('CW0115427928')[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords \n",
        "stopwords = set(stopwords.words('english')) | {'one','may'}\n",
        "# stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "pcRHm7iet_jz"
      },
      "outputs": [],
      "source": [
        "def iter_id_tokens(min_toks=50):\n",
        "    for i,work_id in enumerate(tqdm(df_metadata.work_id, position=0)):\n",
        "        # if i>10: break\n",
        "        for id,toks in get_work_tokens(work_id):\n",
        "            toks = [''.join(x for x in tok if x.isalpha()) for tok in toks]\n",
        "            toks = [tok for tok in toks if len(tok)>2 and tok not in stopwords]\n",
        "            if len(toks)>=min_toks:\n",
        "                yield (id,toks)\n",
        "\n",
        "def iter_tokens():\n",
        "    for id,toks in iter_id_tokens():\n",
        "        yield toks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_KesWR_v36_",
        "outputId": "8c14f532-3a6c-40e5-ba9f-60abd24aba2b"
      },
      "outputs": [],
      "source": [
        "# iter = iter_tokens()\n",
        "# next(iter) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kj2lB4_b_eFO"
      },
      "source": [
        "# Transforming corpus into bag of words vectors\n",
        "\n",
        "We can now perform feature engineering by leveraging a simple Bag of Words\n",
        "model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbCkD1h3wfXY",
        "outputId": "8a24f561-cd13-4626-b1e4-b475bd3234a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2019209"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fn='data.gensim.dictionary.pkl'\n",
        "if not os.path.exists(fn):\n",
        "    dictionary = gensim.corpora.Dictionary(iter_tokens())\n",
        "    dictionary.save(fn)\n",
        "else:\n",
        "    dictionary = gensim.corpora.Dictionary.load(fn)\n",
        "len(dictionary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dictionary.filter_extremes(keep_n=50000)\n",
        "len(dictionary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbDVZkO5wNHv",
        "outputId": "00f27db3-3658-4142-ba1d-7409bb601e83"
      },
      "outputs": [],
      "source": [
        "# Transforming corpus into bag of words vectors\n",
        "def iter_corpus():\n",
        "    for i,page_toks in enumerate(iter_tokens()):\n",
        "        yield dictionary.doc2bow(page_toks)\n",
        "\n",
        "# next(iter_corpus())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "cp_fhm91-3R-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|████▉     | 3462/6939 [17:40<16:35,  3.49it/s]  "
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Transforming corpus into bag of words vectors\n",
        "fn='data.gensim.corpus.mm'\n",
        "gensim.corpora.MmCorpus.serialize(\n",
        "    fn,\n",
        "    iter_corpus(),\n",
        "    id2word=dictionary,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(0, 1.0), (1, 1.0), (2, 1.0), (3, 2.0), (4, 2.0), (5, 1.0), (6, 1.0), (7, 1.0), (8, 1.0), (9, 1.0), (10, 1.0), (11, 1.0), (12, 1.0), (13, 1.0), (14, 1.0), (15, 1.0), (16, 1.0), (17, 1.0), (18, 1.0), (19, 1.0), (20, 1.0), (21, 1.0), (22, 1.0), (23, 1.0), (24, 1.0), (25, 1.0), (26, 1.0), (27, 1.0), (28, 2.0), (29, 1.0), (30, 1.0), (31, 1.0), (32, 1.0), (33, 1.0), (34, 1.0), (35, 1.0), (36, 1.0), (37, 1.0), (38, 1.0), (39, 1.0), (40, 1.0), (41, 1.0), (42, 1.0), (43, 1.0), (44, 1.0), (45, 1.0), (46, 1.0), (47, 1.0), (48, 1.0), (49, 1.0), (50, 1.0), (51, 1.0), (52, 5.0), (53, 1.0), (54, 1.0), (55, 1.0), (56, 1.0), (57, 1.0), (58, 1.0), (59, 1.0), (60, 1.0), (61, 1.0), (62, 1.0), (63, 1.0), (64, 1.0), (65, 1.0), (66, 1.0), (67, 3.0), (68, 1.0), (69, 1.0), (70, 1.0), (71, 1.0), (72, 1.0), (73, 1.0), (74, 1.0), (75, 1.0), (76, 1.0), (77, 1.0), (78, 1.0), (79, 1.0)]\n"
          ]
        }
      ],
      "source": [
        "mm = gensim.corpora.MmCorpus(fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "KUrfWNcWzGx2"
      },
      "outputs": [],
      "source": [
        "TOTAL_TOPICS = 25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "083_UQPlJZy_",
        "outputId": "fd84c9d0-7cc4-4645-9d4f-df2f8ca616f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 1.76 s, sys: 861 ms, total: 2.63 s\n",
            "Wall time: 20.4 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "lda_model = gensim.models.ldamulticore.LdaMulticore(\n",
        "    corpus=mm, \n",
        "    id2word=dictionary,\n",
        "    num_topics=TOTAL_TOPICS,\n",
        "    # chunksize=1740,\n",
        "    # alpha='auto', \n",
        "    # eta='auto', \n",
        "    # random_state=42,\n",
        "    # iterations=500, \n",
        "    # passes=20, \n",
        "    # eval_every=None\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jExj9SYRRyE",
        "outputId": "98ab31fc-8248-4c77-a4f0-53b236c60289"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Avg. Coherence Score: -1.5134945105345707\n"
          ]
        }
      ],
      "source": [
        "topics_coherences = lda_model.top_topics(bow_corpus, topn=20)\n",
        "avg_coherence_score = np.mean([item[1] for item in topics_coherences])\n",
        "print('Avg. Coherence Score:', avg_coherence_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCJwa9dnjvDx"
      },
      "source": [
        "Topic coherence is a complex topic in its own and it can be used to measure the\n",
        "quality of topic models to some extent. Typically, a set of statements is said to be\n",
        "coherent if they support each other. Topic models are unsupervised learning based\n",
        "models that are trained on unstructured text data, making it difficult to measure the\n",
        "quality of outputs.\n",
        "\n",
        "Refer to Text Analytics with Python 2nd Edition for more detail on this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azEdB08qRX4z",
        "outputId": "4ff567d9-98da-4d3b-ba17-35777bbbf953"
      },
      "outputs": [],
      "source": [
        "topics_with_wts = [item[0] for item in topics_coherences]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAkgJa3XRZ3m",
        "outputId": "4f933f78-dd2b-46d1-ed91-b66b3a125c97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LDA Topics without Weights\n",
            "==================================================\n",
            "Topic #1: english, french, first, old, time, great, much, words, latin, man, men, language, like, would, also, two, every, yet, many, must\n",
            "\n",
            "Topic #2: language, words, thought, word, english, would, first, time, great, must, much, upon, many, two, people, see, among, like, man, even\n",
            "\n",
            "Topic #3: would, words, many, language, time, two, latin, great, like, much, sound, man, also, every, people, first, french, even, thus, made\n",
            "\n",
            "Topic #4: english, language, would, words, also, first, time, name, many, french, upon, word, two, well, even, found, see, lines, though, made\n",
            "\n",
            "Topic #5: english, language, man, first, french, every, saxon, name, even, great, words, much, time, like, many, england, word, upon, latin, following\n",
            "\n",
            "Topic #6: thou, loved, love, men, would, first, language, man, upon, shall, words, like, great, thus, two, thought, see, many, time, might\n",
            "\n",
            "Topic #7: words, english, language, upon, every, even, great, two, many, word, latin, well, french, must, would, century, first, nature, said, old\n",
            "\n",
            "Topic #8: language, men, would, english, upon, many, man, word, much, time, also, two, even, every, thus, great, made, could, foot, first\n",
            "\n",
            "Topic #9: men, upon, many, language, first, would, man, though, even, thou, thy, thus, words, god, see, two, english, every, time, like\n",
            "\n",
            "Topic #10: english, first, would, many, language, work, two, form, time, though, century, made, often, long, like, much, general, words, french, lines\n",
            "\n",
            "Topic #11: man, many, first, english, words, thought, language, see, upon, though, two, much, life, would, thou, must, latin, century, could, thus\n",
            "\n",
            "Topic #12: english, time, first, great, language, men, upon, england, two, would, life, latin, french, see, many, words, saxon, made, king, anglo\n",
            "\n",
            "Topic #13: words, english, french, latin, saxon, old, first, many, though, upon, thou, man, two, language, form, anglo, century, well, said, word\n",
            "\n",
            "Topic #14: like, man, words, much, english, rule, two, first, great, form, many, would, shall, thought, language, time, see, men, every, note\n",
            "\n",
            "Topic #15: men, thus, english, first, man, two, time, would, word, thou, many, words, must, also, language, see, upon, lines, much, four\n",
            "\n",
            "Topic #16: words, first, language, two, thought, upon, work, time, like, many, would, men, english, made, even, line, found, sound, every, though\n",
            "\n",
            "Topic #17: english, see, first, language, two, names, great, upon, words, time, said, man, line, century, much, also, thus, men, saxon, latin\n",
            "\n",
            "Topic #18: english, time, upon, part, see, man, thought, words, would, men, great, much, language, king, well, old, poetry, new, work, latin\n",
            "\n",
            "Topic #19: first, like, two, shall, syllable, say, great, thy, know, many, name, english, even, good, see, thus, well, upon, men, lines\n",
            "\n",
            "Topic #20: would, upon, like, language, great, english, men, words, much, nature, man, first, loved, thou, many, could, time, without, well, must\n",
            "\n",
            "Topic #21: rule, english, many, would, mind, upon, language, words, first, latin, great, french, two, thus, ideas, word, form, names, well, name\n",
            "\n",
            "Topic #22: english, upon, two, also, man, great, made, time, foot, first, old, french, much, see, lines, metre, century, far, even, many\n",
            "\n",
            "Topic #23: two, man, great, see, first, thy, thou, upon, like, would, time, death, rule, life, much, thus, thought, king, form, well\n",
            "\n",
            "Topic #24: english, words, language, french, first, thus, man, many, great, saxon, upon, see, thou, reading, time, like, latin, anglo, verse, even\n",
            "\n",
            "Topic #25: english, language, first, england, history, see, name, french, time, great, form, old, que, literature, two, people, much, les, also, norman\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('LDA Topics without Weights')\n",
        "print('='*50)\n",
        "for idx, topic in enumerate(topics_with_wts):\n",
        "    print('Topic #'+str(idx+1)+': '+', '.join([term for wt, term in topic]))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRIZglRTjvDy"
      },
      "source": [
        "## Evaluating topic model quality\n",
        "\n",
        "We can use perplexity and coherence scores as measures to evaluate the topic\n",
        "model. Typically, lower the perplexity, the better the model. Similarly, the lower the\n",
        "UMass score and the higher the Cv score in coherence, the better the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkOZQdZERbzG"
      },
      "outputs": [],
      "source": [
        "cv_coherence_model_lda = gensim.models.CoherenceModel(model=lda_model, corpus=bow_corpus,\n",
        "                                                      texts=iter_tokens(),\n",
        "                                                      dictionary=dictionary,\n",
        "                                                      coherence='c_v')\n",
        "avg_coherence_cv = cv_coherence_model_lda.get_coherence()\n",
        "\n",
        "umass_coherence_model_lda = gensim.models.CoherenceModel(model=lda_model, corpus=bow_corpus,\n",
        "                                                         texts=iter_tokens(),\n",
        "                                                         dictionary=dictionary,\n",
        "                                                         coherence='u_mass')\n",
        "avg_coherence_umass = umass_coherence_model_lda.get_coherence()\n",
        "\n",
        "perplexity = lda_model.log_perplexity(bow_corpus)\n",
        "\n",
        "print('Avg. Coherence Score (Cv):', avg_coherence_cv)\n",
        "print('Avg. Coherence Score (UMass):', avg_coherence_umass)\n",
        "print('Model Perplexity:', perplexity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35TH-ErHjvDz"
      },
      "source": [
        "# LDA Tuning: Finding the optimal number of topics\n",
        "\n",
        "Finding the optimal number of topics in a topic model is tough, given that it is like a\n",
        "model hyperparameter that you always have to set before training the model. We can\n",
        "use an iterative approach and build several models with differing numbers of topics and\n",
        "select the one that has the highest coherence score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYeyeNmRWy4m"
      },
      "outputs": [],
      "source": [
        "def topic_model_coherence_generator(corpus, texts, dictionary,\n",
        "                                    start_topic_count=2, end_topic_count=10, step=1,\n",
        "                                    cpus=1):\n",
        "\n",
        "    models = []\n",
        "    coherence_scores = []\n",
        "    for topic_nums in tqdm.tqdm(range(start_topic_count, end_topic_count+1, step)):\n",
        "        mallet_lda_model = gensim.models.wrappers.LdaMallet(mallet_path=MALLET_PATH, corpus=corpus,\n",
        "                                                            num_topics=topic_nums, id2word=dictionary,\n",
        "                                                            iterations=500, workers=cpus)\n",
        "        cv_coherence_model_mallet_lda = gensim.models.CoherenceModel(model=mallet_lda_model, corpus=corpus,\n",
        "                                                                     texts=texts, dictionary=dictionary,\n",
        "                                                                     coherence='c_v')\n",
        "        coherence_score = cv_coherence_model_mallet_lda.get_coherence()\n",
        "        coherence_scores.append(coherence_score)\n",
        "        models.append(mallet_lda_model)\n",
        "\n",
        "    return models, coherence_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vgKu5RCXHrv"
      },
      "outputs": [],
      "source": [
        "lda_models, coherence_scores = topic_model_coherence_generator(corpus=bow_corpus, texts=norm_corpus_bigrams,\n",
        "                                                               dictionary=dictionary, start_topic_count=2,\n",
        "                                                               end_topic_count=30, step=1, cpus=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EeQIjHsOXPvY"
      },
      "outputs": [],
      "source": [
        "coherence_df = pd.DataFrame({'Number of Topics': range(2, 31, 1),\n",
        "                             'Coherence Score': np.round(coherence_scores, 4)})\n",
        "coherence_df.sort_values(by=['Coherence Score'], ascending=False).head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBSRO_VqYjif"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('fivethirtyeight')\n",
        "%matplotlib inline\n",
        "\n",
        "x_ax = range(2, 31, 1)\n",
        "y_ax = coherence_scores\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(x_ax, y_ax, c='r')\n",
        "plt.axhline(y=0.535, c='k', linestyle='--', linewidth=2)\n",
        "plt.rcParams['figure.facecolor'] = 'white'\n",
        "xl = plt.xlabel('Number of Topics')\n",
        "yl = plt.ylabel('Coherence Score')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5N6wlPjjvD0"
      },
      "source": [
        "We choose the optimal number of topics as 20, based on our intuition. We can retrieve the best model now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtPwVFdrYlxO"
      },
      "outputs": [],
      "source": [
        "best_model_idx = coherence_df[coherence_df['Number of Topics'] == 20].index[0]\n",
        "best_lda_model = lda_models[best_model_idx]\n",
        "best_lda_model.num_topics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQj6L5w4lWXa"
      },
      "outputs": [],
      "source": [
        "topics = [[(term, round(wt, 3))\n",
        "               for term, wt in best_lda_model.show_topic(n, topn=20)]\n",
        "                   for n in range(0, best_lda_model.num_topics)]\n",
        "\n",
        "for idx, topic in enumerate(topics):\n",
        "    print('Topic #'+str(idx+1)+':')\n",
        "    print([term for term, wt in topic])\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOhGwdtzjvD1"
      },
      "source": [
        "# Viewing LDA Model topics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-SpgKYRpHsA"
      },
      "outputs": [],
      "source": [
        "topics_df = pd.DataFrame([[term for term, wt in topic]\n",
        "                              for topic in topics],\n",
        "                         columns = ['Term'+str(i) for i in range(1, 21)],\n",
        "                         index=['Topic '+str(t) for t in range(1, best_lda_model.num_topics+1)]).T\n",
        "topics_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvyOKlu4p7UG"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_colwidth', -1)\n",
        "topics_df = pd.DataFrame([', '.join([term for term, wt in topic])\n",
        "                              for topic in topics],\n",
        "                         columns = ['Terms per Topic'],\n",
        "                         index=['Topic'+str(t) for t in range(1, best_lda_model.num_topics+1)]\n",
        "                         )\n",
        "topics_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efGnYqvIjvD1"
      },
      "source": [
        "# Interpreting Topic Model Results\n",
        "\n",
        "An interesting point to remember is, given a corpus of documents (in the form of\n",
        "features, e.g., Bag of Words) and a trained topic model, you can predict the distribution of\n",
        "topics in each document (research paper in this case).\n",
        "\n",
        "We can now get the most dominant topic per research paper with some intelligent\n",
        "sorting and indexing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXv0NRCXum-I"
      },
      "outputs": [],
      "source": [
        "tm_results = best_lda_model[bow_corpus]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjEHWhVGuuG5"
      },
      "outputs": [],
      "source": [
        "corpus_topics = [sorted(topics, key=lambda record: -record[1])[0]\n",
        "                     for topics in tm_results]\n",
        "corpus_topics[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFmddPmQuyXS"
      },
      "outputs": [],
      "source": [
        "corpus_topic_df = pd.DataFrame()\n",
        "corpus_topic_df['Document'] = range(0, len(papers))\n",
        "corpus_topic_df['Dominant Topic'] = [item[0]+1 for item in corpus_topics]\n",
        "corpus_topic_df['Contribution %'] = [round(item[1]*100, 2) for item in corpus_topics]\n",
        "corpus_topic_df['Topic Desc'] = [topics_df.iloc[t[0]]['Terms per Topic'] for t in corpus_topics]\n",
        "corpus_topic_df['Paper'] = papers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLZ7kcqijvD2"
      },
      "source": [
        "# Dominant Topics Distribution Across Corpus\n",
        "\n",
        "The first thing we can do is look at the overall distribution of each topic across the corpus\n",
        "of research papers. Mainly we want to determine the total number of papers and the\n",
        "total percentage of papers where each of the 20 topics was the most dominant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J95k1tvdu1yP"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_colwidth', 200)\n",
        "topic_stats_df = corpus_topic_df.groupby('Dominant Topic').agg({\n",
        "                                                'Dominant Topic': {\n",
        "                                                    'Doc Count': np.size,\n",
        "                                                    '% Total Docs': np.size }\n",
        "                                              })\n",
        "topic_stats_df = topic_stats_df['Dominant Topic'].reset_index()\n",
        "topic_stats_df['% Total Docs'] = topic_stats_df['% Total Docs'].apply(lambda row: round((row*100) / len(papers), 2))\n",
        "topic_stats_df['Topic Desc'] = [topics_df.iloc[t]['Terms per Topic'] for t in range(len(topic_stats_df))]\n",
        "topic_stats_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkMFJaw-jvD3"
      },
      "source": [
        "# Dominant Topics in Specific Research Papers\n",
        "\n",
        "Another interesting perspective is to select specific papers, view the most dominant topic\n",
        "in each of those papers, and see if that makes sense."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pN45exiiu5sx"
      },
      "outputs": [],
      "source": [
        "corpus_topic_df.groupby('Dominant Topic').apply(lambda topic_set: (topic_set.sort_values(by=['Contribution %'],\n",
        "                                                                                         ascending=False)\n",
        "                                                                             .iloc[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0QF6K53v4zN"
      },
      "outputs": [],
      "source": [
        "sample_paper_patterns = ['Feudal Reinforcement Learning \\nPeter', 'Illumination-Invariant Face Recognition with a', 'Improved Hidden Markov Model Speech Recognition']\n",
        "sample_paper_idxs = [idx for pattern in sample_paper_patterns\n",
        "                            for idx, content in enumerate(papers)\n",
        "                                if pattern in content]\n",
        "sample_paper_idxs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7JrXUbsw0bt"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_colwidth', 200)\n",
        "(corpus_topic_df[corpus_topic_df['Document']\n",
        "                 .isin(sample_paper_idxs)])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
