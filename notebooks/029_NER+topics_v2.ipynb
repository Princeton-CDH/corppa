{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys;sys.path.append('..')\n",
    "from ppanlp import *\n",
    "ppa = PPA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# adding topic models\n",
    "qd=dict(min_doc_len=25,max_per_cluster=50,frac=1)\n",
    "tm = ppa.topic_model(model_type='bertopic', **qd)\n",
    "tdf = tm.mdl.get_topic_info()\n",
    "tdf.columns = [x.lower() for x in tdf]\n",
    "tdf['representative_docs_ids']=[[tm.doc2id[doc] for doc in docs] for docs in tdf.representative_docs]\n",
    "docinfo = tm.mdl.get_document_info(tm.docs)\n",
    "docinfo['page_id']=[tm.doc2id[doc] for doc in docinfo.Document]\n",
    "page2topic = dict(zip(docinfo.page_id,docinfo.Name))\n",
    "# page2topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from scipy.stats.contingency import odds_ratio\n",
    "from scipy.stats import fisher_exact\n",
    "\n",
    "\n",
    "class NERModel:\n",
    "    def __init__(self, corpus=None):\n",
    "        self.corpus = corpus if corpus is not None else PPA()\n",
    "        self.ent2pages=defaultdict(set)\n",
    "        self.ent2count=Counter()\n",
    "        self._annodf=None\n",
    "        \n",
    "    @staticmethod\n",
    "    def clean_ent(ent):\n",
    "        o=ent.strip(punctuation).title()\n",
    "        if o.endswith(\"'S\"): o = o[:-2]\n",
    "        return o\n",
    "    \n",
    "    @staticmethod\n",
    "    def iter_by_page(iterr):\n",
    "        last_pageid=None\n",
    "        last_l=[]\n",
    "        for resd in iterr:\n",
    "            pageid=resd['page_id']\n",
    "            if last_l and pageid!=last_pageid:\n",
    "                yield last_l\n",
    "                last_l=[]\n",
    "            last_l.append(resd)\n",
    "            last_pageid = pageid\n",
    "        if last_l: yield last_l\n",
    "        \n",
    "    def iter_ents(self,ent_types:set=None,lim=None,by_page=False,ents=None):\n",
    "        def iterr():\n",
    "            with self.corpus.ents_db(flag='r') as db:\n",
    "                total=len(db)\n",
    "                iterr=tqdm(db.items(),desc='Iterating over saved ents',position=0,total=total)\n",
    "                for page_id,page_ents in iterr:\n",
    "                    for ent,ent_type in page_ents:\n",
    "                        ent = self.clean_ent(ent)\n",
    "                        if (not ent_types or ent_type in ent_types) and (not ents or ent in ents):\n",
    "                            yield {'page_id':page_id,'ent':self.anno_ents.get(ent,ent),'ent_type':ent_type,'ent_orig':ent}\n",
    "        oiterr = (self.iter_by_page(iterr()) if by_page else iterr())\n",
    "        yield from iterlim(oiterr,lim)\n",
    "    \n",
    "                            \n",
    "    def iter_persons(self, **kwargs):\n",
    "        kwargs['ent_types']={'PERSON'}\n",
    "        yield from self.iter_ents(**kwargs)\n",
    "    \n",
    "    def count_ents(self, **kwargs):\n",
    "        self.ent2count=Counter()\n",
    "        for resd in self.iter_ents(**kwargs):\n",
    "            page_id,ent = resd['page_id'],resd['ent']\n",
    "            self.ent2pages[ent].add(page_id)\n",
    "            self.ent2count[ent]+=1\n",
    "        self.ent2count_s = pd.Series(self.ent2count).sort_values(ascending=False)\n",
    "        return self.ent2count_s\n",
    "    \n",
    "    def count_persons(self, **kwargs):\n",
    "        kwargs['ent_types']={'PERSON'}\n",
    "        return self.count_ents(**kwargs)\n",
    "    \n",
    "    def prep_anno_df(self, min_count=100):\n",
    "        s = ner.ent2count_s\n",
    "        s = s[s>=min_count]\n",
    "        df = pd.DataFrame({'count':s}).rename_axis('name')\n",
    "        df['is_valid'] = ''\n",
    "        return df\n",
    "    \n",
    "    @cached_property\n",
    "    def path_to_anno(self): return os.path.join(self.corpus.path_data, 'data.ner.to_anno.csv')\n",
    "    @cached_property\n",
    "    def path_anno(self): return os.path.join(self.corpus.path_data, 'data.ner.anno.csv')\n",
    "    \n",
    "    def load_anno_df(self, fn=None, force=False):\n",
    "        if force or self._annodf is None:\n",
    "            fn=fn if fn else self.path_anno\n",
    "            self._annodf = pd.read_csv(fn).set_index('name').fillna('')\n",
    "        return self._annodf\n",
    "    \n",
    "    @cached_property\n",
    "    def anno_df(self): return self.load_anno_df()\n",
    "\n",
    "    @cached_property\n",
    "    def anno_ents(self): \n",
    "        df=self.anno_df\n",
    "        df=df[df.is_valid.str.startswith('y')]\n",
    "        return {\n",
    "            k:(v if v else k)\n",
    "            for k,v in zip(df.index, df.who)\n",
    "        }\n",
    "\n",
    "    def iter_ents_anno(self, **kwargs):\n",
    "        kwargs['ents']=set(self.anno_ents.keys())\n",
    "        yield from self.iter_ents(**kwargs)\n",
    "\n",
    "    def iter_persons_anno(self, **kwargs):\n",
    "        kwargs['ent_types']={'PERSON'}\n",
    "        yield from self.iter_ents_anno(**kwargs)\n",
    "        \n",
    "    @cached_property\n",
    "    def persons_anno_pagedata(self):\n",
    "        return [pdata for pdata in self.iter_persons_anno(by_page=True) if pdata]\n",
    "            \n",
    "    def person_cooccurence(self, min_page_count=5, lim=None, funcs = [odds_ratio, fisher_exact], min_count=10, **kwargs):\n",
    "        data = self.persons_anno_pagedata\n",
    "        data = (\n",
    "            random.sample(data,lim) \n",
    "            if lim and len(data)>lim \n",
    "            else data\n",
    "        )\n",
    "        toppref='TOPIC_'\n",
    "        person1 = Counter()\n",
    "        person2 = Counter()\n",
    "        pair_pages = defaultdict(set)\n",
    "        numpages=0\n",
    "        allppl=set()\n",
    "        for pagedata in data:\n",
    "            numpages+=1\n",
    "            pageid=pagedata[0]['page_id']\n",
    "            pageppl = {d['ent'] for d in pagedata}\n",
    "            topic=page2topic.get(pageid)\n",
    "            if topic and not topic.startswith('-1'):\n",
    "                pageppl.add(toppref+topic)\n",
    "            for x in pageppl: \n",
    "                person1[x]+=1\n",
    "                allppl.add(x)\n",
    "                for y in pageppl:\n",
    "                    if x<y:\n",
    "                        person2[x,y]+=1\n",
    "        \n",
    "        def count_ind(x):\n",
    "            return person1[x]\n",
    "        def count_solo(x,y):\n",
    "            return person1[x] - person2[x,y] - person2[y,x]\n",
    "        def count_together(x,y):\n",
    "            return person2[x,y]\n",
    "        def count_neither(x,y):\n",
    "            return numpages - count_together(x,y) - count_solo(x,y) - count_solo(y,x)\n",
    "\n",
    "        person1sum=sum(person1.values())\n",
    "        def prob_ind(x):\n",
    "            return person1[x]/numpages\n",
    "        def prob_obs(x,y):\n",
    "            return person2[x,y]/numpages\n",
    "        def prob_exp(x,y):\n",
    "            return prob_ind(x) * prob_ind(y)\n",
    "        def prob_obsexp(x,y):\n",
    "            return prob_obs(x,y) / prob_exp(x,y)\n",
    "        \n",
    "        \n",
    "        \n",
    "        def get_contingency_table(x,y):\n",
    "            tl=count_together(x,y)\n",
    "            tr=count_solo(x,y)\n",
    "            bl=count_solo(y,x)\n",
    "            br=count_neither(x,y)\n",
    "            return ((tl,tr),(bl,br))\n",
    "        \n",
    "        def iter_res():\n",
    "            minc=min_count\n",
    "            cmps = [(x,y) for x in allppl for y in allppl if x<y and count_ind(x)>=minc and count_ind(y)>=minc]\n",
    "            for x,y in tqdm(cmps):\n",
    "                val_d={\n",
    "                    'person_x':x, \n",
    "                    'person_y':y, \n",
    "                    'num_total_x':count_ind(x), \n",
    "                    'num_total_y':count_ind(y), \n",
    "                    'num_solo_x':count_solo(x,y), \n",
    "                    'num_solo_y':count_solo(y,x),\n",
    "                    'num_both_xy':count_together(x,y), \n",
    "                    'num_neither_xy':count_neither(x,y), \n",
    "                    'prob_x':prob_ind(x)*100,\n",
    "                    'prob_y':prob_ind(y)*100,\n",
    "                    'prob_xy_obs':prob_obs(x,y)*100,\n",
    "                    'prob_xy_exp':prob_exp(x,y)*100,\n",
    "                    'prob_xy_obsexp':prob_obsexp(x,y)*100,\n",
    "                    'includes_topic':x.startswith(toppref) or y.startswith(toppref),\n",
    "                }\n",
    "                ctbl=get_contingency_table(x,y)\n",
    "                for func in funcs:\n",
    "                    res = func(ctbl)\n",
    "                    method=func.__name__\n",
    "                    stat=res.statistic if hasattr(res,'statistic') else None\n",
    "                    pval=res.pvalue if hasattr(res,'pvalue') else None\n",
    "                    if stat is not None: val_d[f'{method}'] = stat\n",
    "                    if pval is not None: val_d[f'{method}_p'] = pval\n",
    "                if val_d.get('fisher_exact_p',1)!=1: \n",
    "                    yield val_d\n",
    "        o=list(iter_res())\n",
    "        return pd.DataFrame() if not o else pd.DataFrame(o).query('fisher_exact_p!=1').sort_values('odds_ratio',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ner = NERModel(ppa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = ner.person_cooccurence(lim=100000, min_count=25)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['prob_xy_obsexp_log']=df['prob_xy_obsexp'].apply(np.log10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfsig = df[df.fisher_exact_p<=.05]\n",
    "# dfsig[dfsig.includes_topic]\n",
    "dfsig_pos = dfsig[dfsig.odds_ratio>1]\n",
    "dfsig_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(377, 500)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "G = nx.Graph()\n",
    "for d in dfsig_pos.to_dict('record')[:500]:\n",
    "    G.add_edge(d['person_x'], d['person_y'], weight=d['prob_xy_obsexp_log'], **d)\n",
    "G.order(),G.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp.nx.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600px\"\n",
       "            src=\"tmp.nx.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x14f2773bad90>"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyvis.network import Network\n",
    "nt = Network(notebook=True, cdn_resources='in_line')\n",
    "nt.from_nx(G)\n",
    "nt.show('tmp.nx.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
