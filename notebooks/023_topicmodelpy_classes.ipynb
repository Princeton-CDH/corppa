{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys;sys.path.append('..')\n",
    "from ppanlp.corpus import PPA\n",
    "from ppanlp.imports import *\n",
    "# import multiprocessing as mp\n",
    "# mp.set_start_method('fork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppa = PPA('~/ppa_data/corpus2', clean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = ppa.topic_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration over texts in PPA:   1%|          | 80/6939 [02:40<3:49:02,  2.00s/it] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/ryanheuser/github/ppa-nlp/notebooks/023_topicmodelpy_classes.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ryanheuser/github/ppa-nlp/notebooks/023_topicmodelpy_classes.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m tm\u001b[39m.\u001b[39;49mprepare_corpus()\n",
      "File \u001b[0;32m~/github/ppa-nlp/notebooks/../ppanlp/topicmodel.py:57\u001b[0m, in \u001b[0;36mPPATopicModel.prepare_corpus\u001b[0;34m(self, force, lim)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[39mfor\u001b[39;00m page \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcorpus\u001b[39m.\u001b[39miter_pages(clean\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclean,lim\u001b[39m=\u001b[39mlim,min_doc_len\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_doc_len,frac\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfrac,frac_text\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfrac_text):\n\u001b[1;32m     51\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mdict\u001b[39m(\n\u001b[1;32m     52\u001b[0m             work_id\u001b[39m=\u001b[39mpage\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39mid,\n\u001b[1;32m     53\u001b[0m             page_id\u001b[39m=\u001b[39mpage\u001b[39m.\u001b[39mid,\n\u001b[1;32m     54\u001b[0m             page_words\u001b[39m=\u001b[39mpage\u001b[39m.\u001b[39mcontent_words\n\u001b[1;32m     55\u001b[0m         )\n\u001b[0;32m---> 57\u001b[0m write_jsonl(\n\u001b[1;32m     58\u001b[0m     iterr(),\n\u001b[1;32m     59\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpath_corpus\n\u001b[1;32m     60\u001b[0m )\n",
      "File \u001b[0;32m~/github/ppa-nlp/notebooks/../ppanlp/utils.py:15\u001b[0m, in \u001b[0;36mwrite_jsonl\u001b[0;34m(obj, fn)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrite_jsonl\u001b[39m(obj, fn):\n\u001b[1;32m     14\u001b[0m     ensure_dir(fn)\n\u001b[0;32m---> 15\u001b[0m     orjsonl\u001b[39m.\u001b[39;49msave(fn, obj)\n",
      "File \u001b[0;32m~/github/ppa-nlp/venv/lib/python3.10/site-packages/orjsonl/orjsonl.py:75\u001b[0m, in \u001b[0;36msave\u001b[0;34m(path, data, default, option, compression_level, compression_threads, compression_format)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Serialize an iterable of Python objects to a compressed or uncompressed UTF-8-encoded jsonl file.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39m    compression_threads (int, optional): An optional integer passed to xopen.xopen() as the 'threads' argument that specifies the number of threads that should be used for compression. Defaults to None.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[39m    compression_format (str, optional): An optional string passed to xopen.xopen() as the 'format' argument that overrides the autodetection of the file's compression format based on its extension. Possible values are 'gz', 'xz', 'bz2' and 'zst'. Defaults to None.\"\"\"\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[39mwith\u001b[39;00m xopen(path, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m, compresslevel\u001b[39m=\u001b[39mcompression_level, threads\u001b[39m=\u001b[39mcompression_threads, \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39mcompression_format) \u001b[39mas\u001b[39;00m writer:\n\u001b[0;32m---> 75\u001b[0m     \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m data:\n\u001b[1;32m     76\u001b[0m         writer\u001b[39m.\u001b[39mwrite(orjson\u001b[39m.\u001b[39mdumps(item, default\u001b[39m=\u001b[39mdefault, option\u001b[39m=\u001b[39moption))\n\u001b[1;32m     77\u001b[0m         writer\u001b[39m.\u001b[39mwrite(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/github/ppa-nlp/notebooks/../ppanlp/topicmodel.py:50\u001b[0m, in \u001b[0;36mPPATopicModel.prepare_corpus.<locals>.iterr\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39miterr\u001b[39m():\n\u001b[0;32m---> 50\u001b[0m     \u001b[39mfor\u001b[39;00m page \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcorpus\u001b[39m.\u001b[39miter_pages(clean\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclean,lim\u001b[39m=\u001b[39mlim,min_doc_len\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_doc_len,frac\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfrac,frac_text\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfrac_text):\n\u001b[1;32m     51\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mdict\u001b[39m(\n\u001b[1;32m     52\u001b[0m             work_id\u001b[39m=\u001b[39mpage\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39mid,\n\u001b[1;32m     53\u001b[0m             page_id\u001b[39m=\u001b[39mpage\u001b[39m.\u001b[39mid,\n\u001b[1;32m     54\u001b[0m             page_words\u001b[39m=\u001b[39mpage\u001b[39m.\u001b[39mcontent_words\n\u001b[1;32m     55\u001b[0m         )\n",
      "File \u001b[0;32m~/github/ppa-nlp/notebooks/../ppanlp/corpus.py:61\u001b[0m, in \u001b[0;36mPPACorpus.iter_pages\u001b[0;34m(self, work_ids, clean, lim, min_doc_len, frac, frac_text)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mif\u001b[39;00m frac_text\u001b[39m==\u001b[39m\u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m random\u001b[39m.\u001b[39mrandom()\u001b[39m<\u001b[39m\u001b[39m=\u001b[39mfrac_text:\n\u001b[1;32m     60\u001b[0m     \u001b[39mfor\u001b[39;00m page \u001b[39min\u001b[39;00m text\u001b[39m.\u001b[39miter_pages(clean\u001b[39m=\u001b[39mclean):\n\u001b[0;32m---> 61\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m min_doc_len \u001b[39mor\u001b[39;00m page\u001b[39m.\u001b[39;49mnum_content_words\u001b[39m>\u001b[39m\u001b[39m=\u001b[39mmin_doc_len:\n\u001b[1;32m     62\u001b[0m             \u001b[39mif\u001b[39;00m frac\u001b[39m==\u001b[39m\u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m random\u001b[39m.\u001b[39mrandom()\u001b[39m<\u001b[39m\u001b[39m=\u001b[39mfrac:\n\u001b[1;32m     63\u001b[0m                 \u001b[39myield\u001b[39;00m page\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/functools.py:981\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[0;34m(self, instance, owner)\u001b[0m\n\u001b[1;32m    979\u001b[0m val \u001b[39m=\u001b[39m cache\u001b[39m.\u001b[39mget(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattrname, _NOT_FOUND)\n\u001b[1;32m    980\u001b[0m \u001b[39mif\u001b[39;00m val \u001b[39mis\u001b[39;00m _NOT_FOUND:\n\u001b[0;32m--> 981\u001b[0m     val \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(instance)\n\u001b[1;32m    982\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    983\u001b[0m         cache[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattrname] \u001b[39m=\u001b[39m val\n",
      "File \u001b[0;32m~/github/ppa-nlp/notebooks/../ppanlp/corpus.py:223\u001b[0m, in \u001b[0;36mPPAPage.num_content_words\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39m@cached_property\u001b[39m\n\u001b[0;32m--> 223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnum_content_words\u001b[39m(\u001b[39mself\u001b[39m): \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcontent_words)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/functools.py:981\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[0;34m(self, instance, owner)\u001b[0m\n\u001b[1;32m    979\u001b[0m val \u001b[39m=\u001b[39m cache\u001b[39m.\u001b[39mget(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattrname, _NOT_FOUND)\n\u001b[1;32m    980\u001b[0m \u001b[39mif\u001b[39;00m val \u001b[39mis\u001b[39;00m _NOT_FOUND:\n\u001b[0;32m--> 981\u001b[0m     val \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(instance)\n\u001b[1;32m    982\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    983\u001b[0m         cache[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattrname] \u001b[39m=\u001b[39m val\n",
      "File \u001b[0;32m~/github/ppa-nlp/notebooks/../ppanlp/corpus.py:221\u001b[0m, in \u001b[0;36mPPAPage.content_words\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[39m@cached_property\u001b[39m\n\u001b[0;32m--> 221\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcontent_words\u001b[39m(\u001b[39mself\u001b[39m): \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_content_words()\n",
      "File \u001b[0;32m~/github/ppa-nlp/notebooks/../ppanlp/corpus.py:228\u001b[0m, in \u001b[0;36mPPAPage.get_content_words\u001b[0;34m(self, min_tok_len)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_content_words\u001b[39m(\u001b[39mself\u001b[39m, min_tok_len\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m):\n\u001b[0;32m--> 228\u001b[0m     \u001b[39mreturn\u001b[39;00m [tok \u001b[39mfor\u001b[39;00m tok \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokens \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(tok)\u001b[39m>\u001b[39m\u001b[39m=\u001b[39mmin_tok_len \u001b[39mand\u001b[39;00m tok \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstopwords]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/functools.py:981\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[0;34m(self, instance, owner)\u001b[0m\n\u001b[1;32m    979\u001b[0m val \u001b[39m=\u001b[39m cache\u001b[39m.\u001b[39mget(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattrname, _NOT_FOUND)\n\u001b[1;32m    980\u001b[0m \u001b[39mif\u001b[39;00m val \u001b[39mis\u001b[39;00m _NOT_FOUND:\n\u001b[0;32m--> 981\u001b[0m     val \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(instance)\n\u001b[1;32m    982\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    983\u001b[0m         cache[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattrname] \u001b[39m=\u001b[39m val\n",
      "File \u001b[0;32m~/github/ppa-nlp/notebooks/../ppanlp/corpus.py:216\u001b[0m, in \u001b[0;36mPPAPage.tokens\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    214\u001b[0m tokens\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeta\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mpage_tokens\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    215\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tokens: tokens\u001b[39m=\u001b[39mtokenize_agnostic(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtxt)\n\u001b[0;32m--> 216\u001b[0m tokens \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mstrip()\u001b[39m.\u001b[39mlower() \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m tokens \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mstrip() \u001b[39mand\u001b[39;00m x\u001b[39m.\u001b[39mstrip()[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39misalpha()]\n\u001b[1;32m    218\u001b[0m \u001b[39mreturn\u001b[39;00m tokens\n",
      "File \u001b[0;32m~/github/ppa-nlp/notebooks/../ppanlp/corpus.py:216\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    214\u001b[0m tokens\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeta\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mpage_tokens\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    215\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tokens: tokens\u001b[39m=\u001b[39mtokenize_agnostic(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtxt)\n\u001b[0;32m--> 216\u001b[0m tokens \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mstrip()\u001b[39m.\u001b[39mlower() \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m tokens \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39;49mstrip() \u001b[39mand\u001b[39;00m x\u001b[39m.\u001b[39mstrip()[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39misalpha()]\n\u001b[1;32m    218\u001b[0m \u001b[39mreturn\u001b[39;00m tokens\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tm.prepare_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tomotopy.LDAModel at 0x1473137b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm.mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02480533, 0.0007205 , 0.00096018, ..., 0.02510548, 0.03688779,\n",
       "        0.20549065],\n",
       "       [0.00036048, 0.0003421 , 0.00616453, ..., 0.00050299, 0.02322318,\n",
       "        0.03477337],\n",
       "       [0.00040176, 0.00038128, 0.00050811, ..., 0.00692299, 0.00043319,\n",
       "        0.00058135],\n",
       "       ...,\n",
       "       [0.01198295, 0.00034806, 0.00046384, ..., 0.00051175, 0.00039545,\n",
       "        0.00053071],\n",
       "       [0.00038699, 0.00036726, 0.00048943, ..., 0.00053998, 0.00041726,\n",
       "        0.00055998],\n",
       "       [0.00038   , 0.00036063, 0.00048059, ..., 0.00053023, 0.15687273,\n",
       "        0.00054987]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm.doc_topic_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving: /Users/ryanheuser/ppa_data/corpus2/data/topicmodels/data.tomotopy.model.ntopic_50.niter_100.clean_None.min_doc_len_25.frac_0.1/ldavis/index.html\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/ryanheuser/ppa_data/corpus2/data/topicmodels/data.tomotopy.model.ntopic_50.niter_100.clean_None.min_doc_len_25.frac_0.1/ldavis/index.html'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm.save_pyldavis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 's' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/ryanheuser/github/ppa-nlp/notebooks/023_topicmodelpy_classes.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ryanheuser/github/ppa-nlp/notebooks/023_topicmodelpy_classes.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m s\n",
      "\u001b[0;31mNameError\u001b[0m: name 's' is not defined"
     ]
    }
   ],
   "source": [
    "s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
